


import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression


data = make_regression(n_samples=1000, n_features=5, noise=0.2, random_state=42)
data[0].shape


X = data[0] # This is our input valules


X[0] # This is our First sample


y = data[1]


y[0]


from sklearn.preprocessing import StandardScaler #Scales the data


scaler = StandardScaler() 
X = scaler.fit_transform(X) # Both fit and transform at the same time we could do this after spliting of test and training sets 


from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


X_train.shape


y_train.shape


import tensorflow as tf


model = tf.keras.models.Sequential(
    [   
        tf.keras.layers.Input(shape = (5, )), # Input layer
        tf.keras.layers.Dense(units = 16, activation = 'relu'), # Fully connted units -> neural number
        tf.keras.layers.Dense(units = 16, activation = 'relu'),
        tf.keras.layers.Dense(units = 1, activation = 'linear'), # Output layer
    ]
)


model.summary()


model = tf.keras.Sequential()
model.add(tf.keras.layers.Input(shape = (5, )))
model.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))


model.summary()


#ALSO CAN USE: from tensorflow.keras.layers import Desnse, Dropout


loss= tf.losses.MeanSquaredError()
opt = tf.optimizers.Adam()
model.compile(loss = loss, optimizer = opt) 


model.fit(X_train, y_train, validation_split = 0.1, epochs = 100, batch_size = 50, verbose = 2) 
# epoches how many times uses loss for the data and optimizer


model.evaluate(X_train, y_train)


model.evaluate(X_test, y_test)


y_pred = model.predict(X_test)


y_pred.shape 


y_test.shape


plt.scatter(y_test, range(200), color = 'blue')
plt.scatter(y_pred, range(200), color = 'red')
